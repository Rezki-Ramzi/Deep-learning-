{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rezki-Ramzi/Deep-learning-/blob/main/Yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s679O9_-_acJ",
        "outputId": "b45412ff-6657-497d-92fa-5389ff1c650a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.5.4-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.8.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.4.0\n",
            "    Uninstalling gdown-4.4.0:\n",
            "      Successfully uninstalled gdown-4.4.0\n",
            "Successfully installed gdown-4.5.4\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1h-fwjkpQ1nEMRETeO_pFyDDLbj7q4V44\n",
            "To: /content/New.zip\n",
            "100% 386M/386M [00:02<00:00, 169MB/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade gdown\n",
        "!gdown 1h-fwjkpQ1nEMRETeO_pFyDDLbj7q4V44"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip New.zip -d ./"
      ],
      "metadata": {
        "id": "HTGIqpvR_pnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONVERT PNG FILES TO JPG\n",
        "from PIL import Image\n",
        "import os\n",
        "path = \"New/\"\n",
        "for im in [f for f in os.listdir(path) if f.endswith(\"png\")]:\n",
        "  img_png = Image.open(path+im)\n",
        "  rgb_im = img_png.convert('RGB')\n",
        "  n = im.split(\".\")[0]\n",
        "  rgb_im.save(path+n+\".jpg\")\n",
        "  os.remove(path+im)"
      ],
      "metadata": {
        "id": "7HeIMB7QAh2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create folders\n",
        "import os\n",
        "os.mkdir(\"data\")\n",
        "os.mkdir(\"data/images\")\n",
        "os.mkdir(\"data/labels\")\n",
        "os.mkdir(\"data/images/train\")\n",
        "os.mkdir(\"data/images/val\")\n",
        "os.mkdir(\"data/images/test\")\n",
        "os.mkdir(\"data/labels/train\")\n",
        "os.mkdir(\"data/labels/val\")\n",
        "os.mkdir(\"data/labels/test\")"
      ],
      "metadata": {
        "id": "_xCcAEh3AjKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# diviser le dataset en 3 parties : \n",
        "# 70% : entrainement\n",
        "# 20% : validation\n",
        "# 10% : test\n",
        "\n",
        "import os\n",
        "import random\n",
        "path = \"New/\"\n",
        "train_img = \"data/images/train/\"\n",
        "val_img = \"data/images/val/\"\n",
        "test_img = \"data/images/test/\"\n",
        "\n",
        "train_lab = \"data/labels/train/\"\n",
        "val_lab = \"data/labels/val/\"\n",
        "test_lab = \"data/labels/test/\"\n",
        "\n",
        "\n",
        "all_imgs = [l.split(\".\")[0] for l in os.listdir(path) if l.endswith(\".jpg\") or l.endswith(\".png\")]\n",
        "random.shuffle(all_imgs) # m√©langer al√©atoirement\n",
        "# print(all_imgs)\n",
        "train = all_imgs[:8580]\n",
        "val = all_imgs[8580:11032]\n",
        "test = all_imgs[11032:]\n",
        "\n",
        "\n",
        "for fi in os.listdir(path):\n",
        "    if fi.split(\".\")[0] in train:\n",
        "      if fi.split(\".\")[-1] in [\"png\",\"jpg\"]:\n",
        "        os.rename(path+fi, train_img+fi)\n",
        "      else:\n",
        "        os.rename(path+fi, train_lab+fi)\n",
        "      \n",
        "    elif fi.split(\".\")[0] in val:\n",
        "        if fi.split(\".\")[-1] in [\"png\",\"jpg\"]:\n",
        "          os.rename(path+fi, val_img+fi)\n",
        "        else:\n",
        "          os.rename(path+fi, val_lab+fi)\n",
        "    else:\n",
        "        if fi.split(\".\")[-1] in [\"png\",\"jpg\"]:\n",
        "          os.rename(path+fi, test_img+fi)\n",
        "        else:\n",
        "          os.rename(path+fi, test_lab+fi)\n",
        "\n"
      ],
      "metadata": {
        "id": "rqQNwUwiAmbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 14gpcpmP-ptTaErF9dHEtmeVXPlsw3amf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBLuz8NcBCtQ",
        "outputId": "00ecd0cf-0e09-42fd-8f14-eeea8fb1acfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14gpcpmP-ptTaErF9dHEtmeVXPlsw3amf\n",
            "To: /content/custom_kag.yaml\n",
            "\r  0% 0.00/164 [00:00<?, ?B/s]\r100% 164/164 [00:00<00:00, 310kB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  \n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA6i8qeuArVX",
        "outputId": "966c23a4-964c-45b9-db72-66f370d69ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14316, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (52/52), done.\u001b[K\n",
            "remote: Total 14316 (delta 37), reused 47 (delta 22), pack-reused 14242\u001b[K\n",
            "Receiving objects: 100% (14316/14316), 13.57 MiB | 23.35 MiB/s, done.\n",
            "Resolving deltas: 100% (9844/9844), done.\n",
            "Setup complete. Using torch 1.12.1+cu113 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1TS279wEK2Hmx2DhqVnMXI7_X84uTySXb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8ILD6CCYYw",
        "outputId": "9e916be9-2f81-4e28-fee7-2bb7c685c65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TS279wEK2Hmx2DhqVnMXI7_X84uTySXb\n",
            "To: /content/best.pt\n",
            "\r  0% 0.00/14.5M [00:00<?, ?B/s]\r 62% 8.91M/14.5M [00:00<00:00, 65.2MB/s]\r100% 14.5M/14.5M [00:00<00:00, 96.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 10 --data custom.yaml --weights best.pt --cache disk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXSEF1abCk98",
        "outputId": "de98e322-53f2-48c1-ac43-ac27c3314a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=best.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=40, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=disk, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-21-ga1b6e79 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 49.8MB/s]\n",
            "Overriding model.yaml nc=4 with nc=3\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from best.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8579 images, 31 backgrounds, 1 corrupt: 100% 8580/8580 [00:04<00:00, 1921.92it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/train/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/train/519.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.1GB disk): 100% 8579/8579 [00:29<00:00, 291.66it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val... 2452 images, 11 backgrounds, 0 corrupt: 100% 2452/2452 [00:05<00:00, 423.63it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/val.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (1.2GB disk): 100% 2452/2452 [00:08<00:00, 273.09it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.27 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
            "Starting training for 40 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/39      14.2G    0.07382    0.05494    0.02045         16        640: 100% 135/135 [03:20<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:28<00:00,  1.44s/it]\n",
            "                   all       2452      10958       0.49      0.556      0.525      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/39      11.7G    0.05421    0.04505   0.003968         13        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      10958      0.405      0.609      0.484      0.176\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/39      11.7G     0.0517    0.04632   0.003086         14        640: 100% 135/135 [03:17<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.36s/it]\n",
            "                   all       2452      10958      0.468      0.549      0.516      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/39      11.7G    0.04955     0.0482   0.002994         31        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.37s/it]\n",
            "                   all       2452      10958      0.569      0.541       0.57      0.239\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/39      11.7G    0.04881    0.04793   0.002656         21        640: 100% 135/135 [03:20<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.36s/it]\n",
            "                   all       2452      10958      0.525      0.482      0.499      0.204\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/39      11.7G    0.04802    0.04806   0.002525         28        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      10958      0.543      0.496      0.515       0.21\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/39      11.7G    0.04753    0.04785   0.002457         19        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.32s/it]\n",
            "                   all       2452      10958      0.562      0.559      0.581      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/39      11.7G    0.04719    0.04772    0.00236         19        640: 100% 135/135 [03:17<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.36s/it]\n",
            "                   all       2452      10958      0.577      0.564      0.588      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/39      11.7G     0.0468    0.04713   0.002322         20        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      10958       0.58       0.55      0.577      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/39      11.7G    0.04647    0.04739   0.002223         21        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.551       0.57      0.583      0.253\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/39      11.7G    0.04612    0.04695   0.002002         15        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.31s/it]\n",
            "                   all       2452      10958      0.575      0.571      0.592      0.261\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/39      11.7G    0.04593    0.04683   0.002037         25        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:28<00:00,  1.44s/it]\n",
            "                   all       2452      10958        0.6      0.574      0.603      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/39      11.7G    0.04579    0.04694   0.002039          8        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.36s/it]\n",
            "                   all       2452      10958      0.588      0.572      0.594      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/39      11.7G    0.04541    0.04611   0.002029         23        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:28<00:00,  1.42s/it]\n",
            "                   all       2452      10958      0.578      0.563      0.586      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/39      11.7G    0.04521     0.0474   0.001846         29        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      10958      0.614       0.57      0.601       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/39      11.7G    0.04506    0.04614    0.00186         12        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.35s/it]\n",
            "                   all       2452      10958      0.604       0.58      0.607      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/39      11.7G    0.04479    0.04665   0.001763         14        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.36s/it]\n",
            "                   all       2452      10958      0.607      0.571      0.606       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/39      11.7G    0.04446    0.04606    0.00175         14        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.598      0.575      0.607      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/39      11.7G    0.04438    0.04578    0.00171         15        640: 100% 135/135 [03:19<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.587      0.572      0.589       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/39      11.7G    0.04396    0.04534   0.001564         11        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.583      0.589      0.601      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/39      11.7G    0.04362    0.04569   0.001668         14        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      10958      0.614      0.589      0.613      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/39      11.7G    0.04354    0.04519    0.00144         13        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.30s/it]\n",
            "                   all       2452      10958      0.588      0.582      0.604       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/39      11.7G     0.0434    0.04553   0.001542         30        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.35s/it]\n",
            "                   all       2452      10958      0.619      0.566      0.598      0.269\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/39      11.7G    0.04316    0.04436   0.001394         15        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.32s/it]\n",
            "                   all       2452      10958      0.618      0.583      0.611      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/39      11.7G    0.04286    0.04474   0.001477         11        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.32s/it]\n",
            "                   all       2452      10958        0.6      0.596      0.611      0.277\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/39      11.7G    0.04236    0.04477   0.001365         35        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.35s/it]\n",
            "                   all       2452      10958      0.615      0.582      0.611      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/39      11.7G    0.04238    0.04389   0.001334         19        640: 100% 135/135 [03:20<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.611      0.594      0.613      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/39      11.7G    0.04211    0.04336   0.001236          8        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.612      0.596      0.613       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/39      11.7G    0.04174    0.04423     0.0013         23        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.35s/it]\n",
            "                   all       2452      10958      0.595      0.597      0.605      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/39      11.7G    0.04156    0.04388   0.001186         20        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:25<00:00,  1.29s/it]\n",
            "                   all       2452      10958      0.615      0.587      0.606      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/39      11.7G    0.04133    0.04366   0.001216         22        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.37s/it]\n",
            "                   all       2452      10958      0.596      0.598      0.607      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/39      11.7G    0.04071    0.04365   0.001091         13        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.30s/it]\n",
            "                   all       2452      10958      0.614       0.59      0.611      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/39      11.7G    0.04073    0.04333   0.001126         20        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.31s/it]\n",
            "                   all       2452      10958      0.614      0.602      0.611      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/39      11.7G    0.04049    0.04356   0.001079         29        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.611      0.596       0.61      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/39      11.7G    0.04028    0.04244    0.00106         12        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.32s/it]\n",
            "                   all       2452      10958      0.609      0.603      0.612      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/39      11.7G    0.03989    0.04251   0.001001         25        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      10958      0.603      0.602      0.605       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/39      11.7G    0.04009     0.0421   0.001005         10        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.32s/it]\n",
            "                   all       2452      10958      0.616      0.601       0.61      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/39      11.7G    0.03936    0.04236  0.0009217         47        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:28<00:00,  1.43s/it]\n",
            "                   all       2452      10958      0.621      0.603      0.612      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/39      11.7G    0.03925    0.04162   0.000832         18        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.31s/it]\n",
            "                   all       2452      10958      0.605      0.606      0.605      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/39      11.7G    0.03899    0.04143   0.001102         15        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:28<00:00,  1.40s/it]\n",
            "                   all       2452      10958      0.612      0.609       0.61      0.284\n",
            "\n",
            "40 epochs completed in 2.523 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating yolov5/runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:30<00:00,  1.52s/it]\n",
            "                   all       2452      10958      0.613      0.608       0.61      0.285\n",
            "                  fire       2452       5746      0.589      0.643       0.62      0.273\n",
            "               no_fire       2452       2102       0.73      0.731      0.793      0.409\n",
            "                 somke       2452       3110       0.52      0.451      0.416      0.172\n",
            "Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 20 --data custom.yaml --weights \"yolov5/runs/train/exp/weights/last.pt\" --cache disk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nj7d8zCAd5FY",
        "outputId": "3f460a34-1a9c-440f-ec5a-b0149c96a2fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/runs/train/exp/weights/last.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=20, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=disk, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "remote: Enumerating objects: 32, done.\u001b[K\n",
            "remote: Counting objects: 100% (32/32), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 19 (delta 14), reused 3 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   a1b6e79..5dc1ce4  master     -> origin/master\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 2 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "YOLOv5 üöÄ v7.0-21-ga1b6e79 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from yolov5/runs/train/exp/weights/last.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8579 images, 35 backgrounds, 1 corrupt: 100% 8580/8580 [00:04<00:00, 1977.25it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/train/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/train/519.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (4.1GB disk): 100% 8579/8579 [00:30<00:00, 283.38it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/test.cache... 1226 images, 3 backgrounds, 0 corrupt: 100% 1226/1226 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.6GB disk): 100% 1226/1226 [00:08<00:00, 138.74it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.26 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/19      14.2G    0.04154    0.04457   0.001393         22        640: 100% 135/135 [03:23<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.47s/it]\n",
            "                   all       1226       5418      0.712      0.731      0.766      0.372\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/19      11.7G    0.04228    0.04496   0.001398         26        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.46s/it]\n",
            "                   all       1226       5418      0.699      0.661      0.706      0.325\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/19      11.7G    0.04387    0.04572   0.001811         11        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.51s/it]\n",
            "                   all       1226       5418      0.556      0.538      0.543       0.23\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/19      11.7G    0.04556    0.04728   0.002034         25        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.51s/it]\n",
            "                   all       1226       5418      0.588       0.58      0.593      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/19      11.7G    0.04568    0.04735   0.002214         17        640: 100% 135/135 [03:20<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.41s/it]\n",
            "                   all       1226       5418      0.614      0.592      0.611      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/19      11.7G    0.04533    0.04725   0.002157         16        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.44s/it]\n",
            "                   all       1226       5418       0.57       0.57      0.597      0.266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/19      11.7G    0.04488    0.04708    0.00185         10        640: 100% 135/135 [03:21<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.49s/it]\n",
            "                   all       1226       5418      0.631      0.573      0.613      0.267\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/19      11.7G    0.04449    0.04699   0.001883         31        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.53s/it]\n",
            "                   all       1226       5418       0.61      0.611      0.621      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/19      11.7G    0.04392     0.0458   0.001761         26        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.58s/it]\n",
            "                   all       1226       5418      0.599      0.606      0.615      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/19      11.7G    0.04362    0.04589    0.00168         14        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.48s/it]\n",
            "                   all       1226       5418      0.607      0.608      0.626      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/19      11.7G    0.04318    0.04535   0.001649         33        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.47s/it]\n",
            "                   all       1226       5418      0.599       0.62       0.64      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/19      11.7G    0.04264    0.04507   0.001562         24        640: 100% 135/135 [03:12<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.58s/it]\n",
            "                   all       1226       5418      0.615      0.611      0.629      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/19      11.7G    0.04251    0.04467   0.001436         17        640: 100% 135/135 [03:11<00:00,  1.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.47s/it]\n",
            "                   all       1226       5418      0.629      0.622       0.65        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/19      11.7G    0.04198    0.04458   0.001273         28        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:16<00:00,  1.61s/it]\n",
            "                   all       1226       5418      0.631      0.629      0.648        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/19      11.7G    0.04143    0.04508   0.001291         26        640: 100% 135/135 [03:14<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.43s/it]\n",
            "                   all       1226       5418      0.635      0.626      0.651      0.305\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/19      11.7G    0.04119     0.0435   0.001177         16        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.59s/it]\n",
            "                   all       1226       5418      0.629       0.62      0.649        0.3\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/19      11.7G    0.04069     0.0441   0.001104         28        640: 100% 135/135 [03:14<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.43s/it]\n",
            "                   all       1226       5418       0.64      0.636      0.651      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/19      11.7G    0.04024     0.0429   0.001031         12        640: 100% 135/135 [03:14<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:15<00:00,  1.56s/it]\n",
            "                   all       1226       5418      0.643      0.644       0.66      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/19      11.7G    0.03986    0.04296   0.001087         22        640: 100% 135/135 [03:13<00:00,  1.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.47s/it]\n",
            "                   all       1226       5418      0.638      0.643      0.662      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/19      11.7G    0.03919    0.04215  0.0009235         19        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:14<00:00,  1.49s/it]\n",
            "                   all       1226       5418      0.648      0.647      0.662      0.313\n",
            "\n",
            "20 epochs completed in 1.181 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 10/10 [00:17<00:00,  1.72s/it]\n",
            "                   all       1226       5418      0.713      0.731      0.766      0.372\n",
            "                  fire       1226       2928      0.683      0.777      0.779      0.373\n",
            "               no_fire       1226       1047      0.775      0.875      0.905       0.45\n",
            "                 somke       1226       1443       0.68      0.541      0.616      0.291\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/val.py --data custom.yaml  --batch 64 --conf 0.001 --weights \"yolov5/runs/train/exp2/weights/last.pt\" \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rcYIWU2wGgG",
        "outputId": "c7347532-68ff-448a-b816-2fa156fba16b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=custom.yaml, weights=['yolov5/runs/train/exp2/weights/last.pt'], batch_size=64, imgsz=640, conf_thres=0.001, iou_thres=0.65, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v7.0-21-ga1b6e79 Python-3.8.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/train... 8580 images, 31 backgrounds, 0 corrupt: 100% 8580/8580 [00:04<00:00, 2011.41it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 135/135 [01:52<00:00,  1.20it/s]\n",
            "                   all       8580      38784      0.743      0.742      0.785      0.402\n",
            "                  fire       8580      20655      0.725       0.78      0.798        0.4\n",
            "               no_fire       8580       7479      0.804      0.835      0.891      0.478\n",
            "                 somke       8580      10650        0.7      0.611      0.666      0.329\n",
            "Speed: 0.2ms pre-process, 6.4ms inference, 1.3ms NMS per image at shape (64, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp8\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 10 --data custom.yaml --weights last5.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGS9waNu6Ued",
        "outputId": "ff34c0e2-07a2-404e-d7f3-1937ec026dc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last5.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop>=0.1.1) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop>=0.1.1) (4.4.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ v7.0-30-g342fe05 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients\n",
            "\n",
            "Transferred 349/349 items from last5.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8579 images, 28 backgrounds, 1 corrupt: 100% 8580/8580 [00:04<00:00, 1758.15it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/train/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/train/519.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m9.8GB RAM required, 9.6/12.7GB available, not caching images ‚ö†Ô∏è\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 2452 images, 16 backgrounds, 0 corrupt: 100% 2452/2452 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.8GB ram): 100% 2452/2452 [00:13<00:00, 185.22it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.27 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      14.2G    0.03857    0.04147  0.0008376         18        640: 100% 135/135 [03:26<00:00,  1.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.17s/it]\n",
            "                   all       2452      11129      0.793      0.803      0.859      0.459\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      11.7G    0.03847    0.04098  0.0008737         20        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.13s/it]\n",
            "                   all       2452      11129      0.781        0.8      0.853      0.453\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      11.7G    0.03871    0.04172  0.0009049         25        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.14s/it]\n",
            "                   all       2452      11129      0.776      0.784      0.839       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      11.7G    0.03848    0.04137  0.0008984         33        640: 100% 135/135 [03:20<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.11s/it]\n",
            "                   all       2452      11129      0.767      0.784      0.832      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      11.7G    0.03863    0.04122   0.000845         18        640: 100% 135/135 [03:21<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      11129      0.758      0.778      0.828       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      11.7G    0.03833    0.04111  0.0008654         27        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.15s/it]\n",
            "                   all       2452      11129       0.77      0.776      0.828      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      11.7G    0.03818    0.04047  0.0008809         12        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      11129      0.762      0.781      0.825      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      11.7G    0.03807    0.04071  0.0008589         12        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      11129      0.759      0.776      0.823       0.43\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      11.7G    0.03797    0.04034  0.0008428         25        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:21<00:00,  1.10s/it]\n",
            "                   all       2452      11129       0.76      0.775      0.825      0.433\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      11.7G    0.03786    0.04041  0.0008406         10        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.10s/it]\n",
            "                   all       2452      11129       0.76      0.781      0.826      0.434\n",
            "\n",
            "10 epochs completed in 0.618 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating yolov5/runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.34s/it]\n",
            "                   all       2452      11129      0.794      0.802      0.859      0.459\n",
            "                  fire       2452       5870      0.784      0.824      0.865      0.453\n",
            "               no_fire       2452       2178      0.841      0.876      0.934       0.51\n",
            "                 somke       2452       3081      0.758      0.706      0.779      0.413\n",
            "Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/val.py --data custom.yaml  --batch 100 --conf 0.001 --weights yolov5/runs/train/exp/weights/last.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Cyflzs7kFl",
        "outputId": "3eb6d711-d4f9-46e7-a0e0-a3e4c4c5993c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=custom.yaml, weights=['yolov5/runs/train/exp/weights/last.pt'], batch_size=100, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v7.0-30-g342fe05 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val... 2452 images, 10 backgrounds, 0 corrupt: 100% 2452/2452 [00:01<00:00, 1997.22it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:33<00:00,  1.34s/it]\n",
            "                   all       2452      10967      0.791      0.812      0.864      0.467\n",
            "                  fire       2452       5886      0.779       0.83      0.865       0.46\n",
            "               no_fire       2452       2059      0.825      0.884      0.931      0.511\n",
            "                 somke       2452       3022      0.768      0.722      0.797      0.428\n",
            "Speed: 0.4ms pre-process, 6.3ms inference, 1.4ms NMS per image at shape (100, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1dotLmwqbkw5z9NNf3gJk4V0WID3ZChcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpNMNUnTGHr3",
        "outputId": "094a16fd-06d7-449c-bbfc-db9e9fb34cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dotLmwqbkw5z9NNf3gJk4V0WID3ZChcc\n",
            "To: /content/last6.pt\n",
            "\r  0% 0.00/14.4M [00:00<?, ?B/s]\r100% 14.4M/14.4M [00:00<00:00, 145MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 10 --data custom.yaml --weights last6.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QsHXgavGHut",
        "outputId": "9595016f-3fdf-4036-914b-7a3a66e0c467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last6.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-30-g342fe05 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from last6.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8579 images, 34 backgrounds, 1 corrupt: 100% 8580/8580 [00:04<00:00, 2021.72it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/train/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/train/519.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m9.8GB RAM required, 9.4/12.7GB available, not caching images ‚ö†Ô∏è\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 2452 images, 10 backgrounds, 0 corrupt: 100% 2452/2452 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.8GB ram): 100% 2452/2452 [00:13<00:00, 184.92it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.28 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      14.2G    0.03844    0.04174  0.0009006         26        640: 100% 135/135 [03:26<00:00,  1.53s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.17s/it]\n",
            "                   all       2452      10967      0.798      0.799      0.863      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      11.7G    0.03813    0.04147  0.0008651         22        640: 100% 135/135 [03:18<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      10967      0.783       0.81      0.858      0.458\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      11.7G    0.03867    0.04139  0.0008599          9        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.19s/it]\n",
            "                   all       2452      10967      0.777      0.793      0.847      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      11.7G    0.03837    0.04132  0.0008629         27        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.15s/it]\n",
            "                   all       2452      10967      0.755      0.791      0.839       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      11.7G    0.03804    0.04104  0.0008823         23        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.15s/it]\n",
            "                   all       2452      10967      0.765      0.788      0.834       0.44\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      11.7G    0.03827    0.04089  0.0008407         17        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.16s/it]\n",
            "                   all       2452      10967      0.766      0.773       0.83      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      11.7G    0.03791    0.04091   0.000824         15        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      10967      0.756      0.787      0.829      0.437\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      11.7G    0.03764    0.04101  0.0008607         16        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2452      10967      0.759      0.777      0.829      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      11.7G    0.03768    0.04069  0.0007828         29        640: 100% 135/135 [03:17<00:00,  1.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:21<00:00,  1.09s/it]\n",
            "                   all       2452      10967       0.76       0.78      0.831      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      11.7G    0.03753    0.04039  0.0008253         11        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.14s/it]\n",
            "                   all       2452      10967      0.764      0.776       0.83      0.437\n",
            "\n",
            "10 epochs completed in 0.615 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.35s/it]\n",
            "                   all       2452      10967      0.797        0.8      0.863      0.465\n",
            "                  fire       2452       5886      0.793      0.821      0.865       0.46\n",
            "               no_fire       2452       2059      0.833      0.875      0.933      0.506\n",
            "                 somke       2452       3022      0.766      0.703      0.791      0.428\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1HmI5_VSB-x3Iy25LgX8-D6Z4RTTQDXQB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kbi8uJx_dgN",
        "outputId": "30a3ebb6-79e0-47a0-e63d-d1c2e79b25b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HmI5_VSB-x3Iy25LgX8-D6Z4RTTQDXQB\n",
            "To: /content/last9.pt\n",
            "\r  0% 0.00/14.4M [00:00<?, ?B/s]\r100% 14.4M/14.4M [00:00<00:00, 258MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 10 --data custom.yaml --weights last9.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lTvSLg4_r3K",
        "outputId": "ee9a7400-1cdc-414d-a3a5-3a255c950c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last9.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "YOLOv5 üöÄ v7.0-30-g342fe05 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients, 16.0 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from last9.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8580 images, 43 backgrounds, 0 corrupt: 100% 8580/8580 [00:04<00:00, 2033.08it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m9.8GB RAM required, 9.4/12.7GB available, not caching images ‚ö†Ô∏è\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 2451 images, 4 backgrounds, 1 corrupt: 100% 2452/2452 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/val/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/val/519.jpg'\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.8GB ram): 100% 2451/2451 [00:13<00:00, 182.17it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.27 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      14.2G    0.03764    0.04082  0.0007592         31        640: 100% 135/135 [03:37<00:00,  1.61s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:24<00:00,  1.23s/it]\n",
            "                   all       2451      11220      0.795      0.825      0.869      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      11.7G    0.03779    0.04046   0.000923         15        640: 100% 135/135 [03:27<00:00,  1.54s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:24<00:00,  1.20s/it]\n",
            "                   all       2451      11220      0.794      0.811      0.863      0.463\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      11.7G    0.03784    0.04085   0.000779         12        640: 100% 135/135 [03:22<00:00,  1.50s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:24<00:00,  1.21s/it]\n",
            "                   all       2451      11220      0.788      0.806      0.853      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      11.7G    0.03793    0.04094  0.0008033         36        640: 100% 135/135 [03:24<00:00,  1.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:24<00:00,  1.22s/it]\n",
            "                   all       2451      11220      0.768      0.804      0.846      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      11.7G    0.03786    0.04049    0.00093         17        640: 100% 135/135 [03:24<00:00,  1.52s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.18s/it]\n",
            "                   all       2451      11220      0.767      0.793      0.839      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      11.7G     0.0377    0.04055  0.0007976         27        640: 100% 135/135 [03:22<00:00,  1.50s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.19s/it]\n",
            "                   all       2451      11220      0.766      0.791      0.836      0.442\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      11.7G    0.03759    0.04066  0.0007833         24        640: 100% 135/135 [03:21<00:00,  1.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.17s/it]\n",
            "                   all       2451      11220      0.758      0.804      0.837      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      11.7G    0.03738    0.04064  0.0007792         54        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.20s/it]\n",
            "                   all       2451      11220      0.769      0.792      0.838      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      11.7G    0.03712    0.03987  0.0006995         21        640: 100% 135/135 [03:20<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.12s/it]\n",
            "                   all       2451      11220      0.765      0.796      0.838      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      11.7G    0.03723    0.04031  0.0008138         31        640: 100% 135/135 [03:19<00:00,  1.48s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.17s/it]\n",
            "                   all       2451      11220       0.76      0.795      0.834      0.447\n",
            "\n",
            "10 epochs completed in 0.635 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from yolov5/runs/train/exp2/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating yolov5/runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:27<00:00,  1.39s/it]\n",
            "                   all       2451      11220      0.794      0.826      0.869      0.473\n",
            "                  fire       2451       6033      0.792       0.84      0.874      0.469\n",
            "               no_fire       2451       2182      0.837      0.894      0.933      0.509\n",
            "                 somke       2451       3005      0.754      0.744      0.801      0.442\n",
            "Results saved to \u001b[1myolov5/runs/train/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/val.py --data custom.yaml  --batch 100 --conf 0.001 --weights yolov5/runs/train/exp2/weights/last.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO91KMjJ_ww8",
        "outputId": "88ad0b49-5124-43d3-d04e-930f2a382285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=custom.yaml, weights=['yolov5/runs/train/exp2/weights/last.pt'], batch_size=100, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v7.0-30-g342fe05 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val... 2452 images, 10 backgrounds, 0 corrupt: 100% 2452/2452 [00:01<00:00, 2123.93it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:35<00:00,  1.43s/it]\n",
            "                   all       2452      10959      0.799      0.828      0.877      0.485\n",
            "                  fire       2452       5766      0.794      0.853      0.883      0.474\n",
            "               no_fire       2452       2123      0.831      0.883      0.937      0.521\n",
            "                 somke       2452       3070      0.771      0.749      0.812      0.459\n",
            "Speed: 0.7ms pre-process, 6.0ms inference, 1.7ms NMS per image at shape (100, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py  --batch 64 --epochs 10 --data custom.yaml --weights last11.pt --cache"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K65CddxypqyE",
        "outputId": "5bd49204-ab14-4a0c-ba20-dd8f408c8a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=last11.pt, cfg=, data=custom.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=64, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirement \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop>=0.1.1) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop>=0.1.1) (4.4.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 1 package updated per /content/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ v7.0-31-g443ef7f Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.001, lrf=0.001, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5], [0, 1, 2, 3, 4, 5]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7027720 parameters, 7027720 gradients\n",
            "\n",
            "Transferred 349/349 items from last11.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.001) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data/labels/train... 8579 images, 32 backgrounds, 1 corrupt: 100% 8580/8580 [00:05<00:00, 1617.84it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /content/data/images/train/519.jpg: ignoring corrupt image/label: cannot identify image file '/content/data/images/train/519.jpg'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data/labels/train.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m9.8GB RAM required, 9.5/12.7GB available, not caching images ‚ö†Ô∏è\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val.cache... 2452 images, 13 backgrounds, 0 corrupt: 100% 2452/2452 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (2.8GB ram): 100% 2452/2452 [00:13<00:00, 179.25it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.28 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to yolov5/runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1myolov5/runs/train/exp\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      14.2G    0.03743    0.04057  0.0007123         23        640: 100% 135/135 [03:27<00:00,  1.54s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.16s/it]\n",
            "                   all       2452      11024      0.795       0.83      0.874      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      11.7G    0.03717    0.04003  0.0007851         21        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.14s/it]\n",
            "                   all       2452      11024      0.785      0.828      0.869      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      11.7G    0.03713    0.03994  0.0006976         14        640: 100% 135/135 [03:16<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:23<00:00,  1.16s/it]\n",
            "                   all       2452      11024      0.773      0.816      0.857      0.464\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      11.7G    0.03727    0.04055  0.0007688         29        640: 100% 135/135 [03:17<00:00,  1.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.10s/it]\n",
            "                   all       2452      11024      0.783      0.802      0.851      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      11.7G    0.03728    0.04042  0.0006831         35        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.11s/it]\n",
            "                   all       2452      11024      0.766      0.795      0.843      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      11.7G     0.0372    0.04006  0.0006806         19        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:21<00:00,  1.10s/it]\n",
            "                   all       2452      11024      0.765      0.797      0.841      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      11.7G    0.03714    0.04014  0.0007058         22        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:21<00:00,  1.08s/it]\n",
            "                   all       2452      11024      0.768      0.795      0.842       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      11.7G    0.03689    0.03977  0.0007018         18        640: 100% 135/135 [03:16<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:21<00:00,  1.10s/it]\n",
            "                   all       2452      11024      0.761      0.798      0.836      0.449\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      11.7G     0.0367    0.03913  0.0006156         14        640: 100% 135/135 [03:14<00:00,  1.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.13s/it]\n",
            "                   all       2452      11024      0.767      0.795       0.84       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      11.7G    0.03669    0.03933  0.0006662          9        640: 100% 135/135 [03:15<00:00,  1.45s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:22<00:00,  1.10s/it]\n",
            "                   all       2452      11024      0.754      0.803      0.837       0.45\n",
            "\n",
            "10 epochs completed in 0.612 hours.\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from yolov5/runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating yolov5/runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 20/20 [00:26<00:00,  1.33s/it]\n",
            "                   all       2452      11024      0.794      0.831      0.874      0.483\n",
            "                  fire       2452       5873      0.802      0.844      0.884      0.479\n",
            "               no_fire       2452       2132      0.818      0.898      0.932      0.515\n",
            "                 somke       2452       3019       0.76      0.752      0.807      0.454\n",
            "Results saved to \u001b[1myolov5/runs/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/val.py --data custom.yaml  --batch 100 --conf 0.001 --weights yolov5/runs/train/exp/weights/last.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLaiFhTd1V3n",
        "outputId": "f77eb3fc-7574-4b33-9b7e-2f95eacb017b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=custom.yaml, weights=['yolov5/runs/train/exp/weights/last.pt'], batch_size=100, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v7.0-31-g443ef7f Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels/val... 2452 images, 8 backgrounds, 0 corrupt: 100% 2452/2452 [00:01<00:00, 2145.92it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data/labels/val.cache\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:33<00:00,  1.35s/it]\n",
            "                   all       2452      11017      0.801      0.839      0.886      0.494\n",
            "                  fire       2452       5808      0.801      0.874      0.896        0.5\n",
            "               no_fire       2452       2124      0.812      0.888      0.932      0.507\n",
            "                 somke       2452       3085       0.79      0.754      0.829      0.473\n",
            "Speed: 0.3ms pre-process, 6.4ms inference, 1.6ms NMS per image at shape (100, 3, 640, 640)\n",
            "Results saved to \u001b[1myolov5/runs/val/exp2\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}