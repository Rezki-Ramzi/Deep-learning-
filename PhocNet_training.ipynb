{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rezki-Ramzi/Deep-learning-/blob/main/PhocNet_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtYCJf1YhIe1"
      },
      "outputs": [],
      "source": [
        "# la taille de vecteur phoc est 604 \n",
        "# word : chaine de caracters\n",
        "bigram = ['th', 'he', 'in', 'er', 'an', 're', 'es', 'on', 'st', 'nt', 'en',\n",
        "'at', 'ed', 'nd', 'to', 'or', 'ea', 'ti', 'ar', 'te', 'ng', 'al',\n",
        "'it', 'as', 'is', 'ha', 'et', 'se', 'ou', 'of', 'le', 'sa', 've',\n",
        "'ro', 'ra', 'hi', 'ne', 'me', 'de', 'co', 'ta', 'ec', 'si', 'll',\n",
        "'so', 'na', 'li', 'la', 'el', 'ma']\n",
        "def generate_36(word):\n",
        "  vector_36 = [0 for i in range(36)]\n",
        "  for char in word:\n",
        "    if char.isdigit():\n",
        "      vector_36[ord(char) - ord('0')] = 1\n",
        "    elif char.isalpha():\n",
        "      vector_36[10+ord(char) - ord('a')] = 1\n",
        "  return vector_36\n",
        "\n",
        "def generate_50(word):\n",
        "  vector_50 = [0 for i in range(50)]\n",
        "  for big in bigram:\n",
        "    if big in word:\n",
        "      vector_50[bigram.index(big)]=1\n",
        "  # print(\"the 50 bigram vector is\",vector_50)\n",
        "  return vector_50\n",
        "\n",
        "\n",
        "def generate_label(word):\n",
        "  word = word.lower()\n",
        "  vector = []\n",
        "  L = len(word)\n",
        "  for split in range(2, 6):\n",
        "    parts = L//split\n",
        "    for mul in range(split-1):\n",
        "      vector += generate_36(word[mul*parts:mul*parts+parts])\n",
        "    vector += generate_36(word[(split-1)*parts:L])\n",
        "\n",
        "  # diviser le mot word en 2 sous mots ici:\n",
        "  vector += generate_50(word[0:L//2])\n",
        "  vector += generate_50(word[L//2: L])\n",
        "  #   print(\"la representation phoc de \" + word +\"est donnée comme suit :\",vector)\n",
        "  # print(\"################################\")  \n",
        "  return vector\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word=\"mohammed\"\n",
        "print(generate_label(word))\n",
        "len(generate_label(word))\n",
        "# print(sum(generate_label(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPdkb1yahQJc",
        "outputId": "1e3075e5-9e8b-4133-fc83-a3739e8f4bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten,Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras import losses\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "zNzcZwHQhQQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/OmarBoudraa/PUNET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tiomt2LihQXa",
        "outputId": "4bd18aed-9e71-4c27-af8c-eed2f70c28e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PUNET'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Total 148 (delta 0), reused 0 (delta 0), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (148/148), 58.39 MiB | 12.38 MiB/s, done.\n",
            "Resolving deltas: 100% (58/58), done.\n",
            "Updating files: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "import encodings\n",
        "from xml.etree import ElementTree as ET\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "# WORD_IMAGE_DIR = 'words/'\n",
        "XML_DIR = './PUNET/xml/'\n",
        "GW_DIR = './PUNET/images/'\n",
        "transcripts = {}\n",
        "\n",
        "def append_data(x, y, transcript, data): # need not return anything\n",
        "    x.append(data[0])\n",
        "    y.append(data[1])\n",
        "    transcript.append(data[2])\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    time_start = datetime.now()\n",
        "\n",
        "    xml_files = glob(XML_DIR+'*.xml')\n",
        "    print(\"taille : \",len(xml_files))\n",
        "    x_train = []\n",
        "    y_train = []\n",
        "    train_transcript = []\n",
        "    x_valid = []\n",
        "    y_valid = []\n",
        "    valid_transcript = []\n",
        "    x_test = []\n",
        "    y_test = []\n",
        "    test_transcript = []\n",
        "    global transcripts\n",
        "    \n",
        "    for xml_file in xml_files:\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        xml_file_name = os.path.splitext(xml_file)[0]\n",
        "        print(xml_file_name)\n",
        "        # Change this code to get the corresponsing word image dir\n",
        "        # image_dir = xml_file.split('/')[-1].split('.')[0].split('-')\n",
        "        # image_dir = image_dir[0] + '/' + image_dir[0]+'-'+image_dir[1]+ '/'\n",
        "        image_dir = GW_DIR # + image_dir\n",
        "\n",
        "        for word_idx, word_elem in enumerate(root.findall('spot')):\n",
        "        # for word in root.iter('word'):\n",
        "            img_id = word_elem.attrib['image'].split('.')[0]\n",
        "            img_name = image_dir+img_id+'.tif'\n",
        "            img_transcript = word_elem.attrib['word'].lower()\n",
        "            #img_transcript = word.get('text').lower()\n",
        "\n",
        "            im = cv2.imread(img_name, 0)\n",
        "            #height = np.size(im, 0)\n",
        "            #print(height)\n",
        "            x = int(word_elem.attrib['x'])\n",
        "            y = int(word_elem.attrib['y'])\n",
        "            h = int(word_elem.attrib['h'])\n",
        "            w = int(word_elem.attrib['w'])\n",
        "            img = im[y:y+h,x:x+w]\n",
        "            #height = np.size(img, 0)\n",
        "            #print(height)\n",
        "            if img is None: # Some image files are corrupted\n",
        "                continue\n",
        "\n",
        "            target = generate_label(img_transcript)\n",
        "            if sum(target) == 0: # For special characters\n",
        "                img_transcript = '' # Use a special notation for them\n",
        "\n",
        "            img = cv2.resize(img, (100,50))  # phoc requis\n",
        "            # img = cv2.resize(img, (224,224))   #vgg requis\n",
        "            img = np.where(img<200, 1, 0)\n",
        "            img = img[:, :, np.newaxis]\n",
        "\n",
        "            data = [img, target, img_transcript]\n",
        "            # print(xml_file_name)\n",
        "            if xml_file_name == './PUNET/xml/gw_cv1_train' or xml_file_name == './PUNET/xml/gw_cv2_train':\n",
        "                # print(\"train --------------\")\n",
        "                append_data(x_train, y_train, train_transcript, data)\n",
        "            elif xml_file_name == './PUNET/xml/gw_cv3_val':\n",
        "                append_data(x_valid, y_valid, valid_transcript, data)\n",
        "            elif xml_file_name == './PUNET/xml/gw_cv4_test':\n",
        "                append_data(x_test, y_test, test_transcript, data)\n",
        "            else:\n",
        "              print(\"sinon !!\")    \n",
        "\n",
        "    N = len(x_train) + len(x_valid) + len(x_test)\n",
        "\n",
        "    x_train = np.array(x_train)\n",
        "    y_train = np.array(y_train)\n",
        "    train_trainscript = np.array(train_transcript)\n",
        "\n",
        "    x_valid = np.array(x_valid)\n",
        "    y_valid = np.array(y_valid)\n",
        "    valid_transcript = np.array(valid_transcript)\n",
        "\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test)\n",
        "    test_transcript = np.array(test_transcript)\n",
        "\n",
        "    print (\"Time to fetch data: \", datetime.now() - time_start)\n",
        "\n",
        "    return (x_train, y_train, train_transcript,\n",
        "            x_valid, y_valid, valid_transcript,\n",
        "            x_test, y_test, test_transcript)\n"
      ],
      "metadata": {
        "id": "4UO_tuR_hQdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, train_transcript,x_valid, y_valid, valid_transcript,x_test, y_test, test_transcript = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWmCnIM4hQhi",
        "outputId": "0004c792-69c0-4d79-af87-186fb25ca56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "taille :  4\n",
            "./PUNET/xml/gw_cv3_val\n",
            "./PUNET/xml/gw_cv1_train\n",
            "./PUNET/xml/gw_cv4_test\n",
            "./PUNET/xml/gw_cv2_train\n",
            "Time to fetch data:  0:01:22.660808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "from keras.layers import Layer\n",
        "# from github avec des changements de tf et th ... \n",
        "class SpatialPyramidPooling(Layer):\n",
        "  \n",
        "    def __init__(self, pool_list, **kwargs):\n",
        "\n",
        "        self.dim_ordering = K.image_data_format()\n",
        "        print(self.dim_ordering)\n",
        "        assert self.dim_ordering in {'channels_last', 'channels_first'}, 'dim_ordering must be in {tf, th}'\n",
        "\n",
        "        self.pool_list = pool_list\n",
        "\n",
        "        self.num_outputs_per_channel = sum([i * i for i in pool_list])\n",
        "\n",
        "        super(SpatialPyramidPooling, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.dim_ordering == 'channels_first':\n",
        "            self.nb_channels = input_shape[1]\n",
        "        elif self.dim_ordering == 'channels_last':\n",
        "            self.nb_channels = input_shape[3]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0], self.nb_channels * self.num_outputs_per_channel)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'pool_list': self.pool_list}\n",
        "        base_config = super(SpatialPyramidPooling, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        input_shape = K.shape(x)\n",
        "\n",
        "        if self.dim_ordering == 'channels_first':\n",
        "            num_rows = input_shape[2]\n",
        "            num_cols = input_shape[3]\n",
        "        elif self.dim_ordering == 'channels_last':\n",
        "            num_rows = input_shape[1]\n",
        "            num_cols = input_shape[2]\n",
        "\n",
        "        row_length = [K.cast(num_rows, 'float32') / i for i in self.pool_list]\n",
        "        col_length = [K.cast(num_cols, 'float32') / i for i in self.pool_list]\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        if self.dim_ordering == 'channels_first':\n",
        "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
        "                for jy in range(num_pool_regions):\n",
        "                    for ix in range(num_pool_regions):\n",
        "                        x1 = ix * col_length[pool_num]\n",
        "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
        "                        y1 = jy * row_length[pool_num]\n",
        "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
        "\n",
        "                        x1 = K.cast(K.round(x1), 'int32')\n",
        "                        x2 = K.cast(K.round(x2), 'int32')\n",
        "                        y1 = K.cast(K.round(y1), 'int32')\n",
        "                        y2 = K.cast(K.round(y2), 'int32')\n",
        "                        new_shape = [input_shape[0], input_shape[1],\n",
        "                                     y2 - y1, x2 - x1]\n",
        "                        x_crop = x[:, :, y1:y2, x1:x2]\n",
        "                        xm = K.reshape(x_crop, new_shape)\n",
        "                        pooled_val = K.max(xm, axis=(2, 3))\n",
        "                        outputs.append(pooled_val)\n",
        "\n",
        "        elif self.dim_ordering == 'channels_last':\n",
        "            for pool_num, num_pool_regions in enumerate(self.pool_list):\n",
        "                for jy in range(num_pool_regions):\n",
        "                    for ix in range(num_pool_regions):\n",
        "                        x1 = ix * col_length[pool_num]\n",
        "                        x2 = ix * col_length[pool_num] + col_length[pool_num]\n",
        "                        y1 = jy * row_length[pool_num]\n",
        "                        y2 = jy * row_length[pool_num] + row_length[pool_num]\n",
        "\n",
        "                        x1 = K.cast(K.round(x1), 'int32')\n",
        "                        x2 = K.cast(K.round(x2), 'int32')\n",
        "                        y1 = K.cast(K.round(y1), 'int32')\n",
        "                        y2 = K.cast(K.round(y2), 'int32')\n",
        "\n",
        "                        new_shape = [input_shape[0], y2 - y1,\n",
        "                                     x2 - x1, input_shape[3]]\n",
        "\n",
        "                        x_crop = x[:, y1:y2, x1:x2, :]\n",
        "                        xm = K.reshape(x_crop, new_shape)\n",
        "                        pooled_val = K.max(xm, axis=(1, 2))\n",
        "                        outputs.append(pooled_val)\n",
        "\n",
        "        if self.dim_ordering == 'channels_first':\n",
        "            outputs = K.concatenate(outputs)\n",
        "        elif self.dim_ordering == 'channels_last':\n",
        "            #outputs = K.concatenate(outputs,axis = 1)\n",
        "            outputs = K.concatenate(outputs)\n",
        "            #outputs = K.reshape(outputs,(len(self.pool_list),self.num_outputs_per_channel,input_shape[0],input_shape[1]))\n",
        "            #outputs = K.permute_dimensions(outputs,(3,1,0,2))\n",
        "            #outputs = K.reshape(outputs,(input_shape[0], self.num_outputs_per_channel * self.nb_channels))\n",
        "\n",
        "        return outputs\n"
      ],
      "metadata": {
        "id": "qI0034vehQn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class BinarizationLayer(Layer):\n",
        "#     def __init__(self, threshold=0.5, **kwargs):\n",
        "#         super().__init__(**kwargs)\n",
        "#         self.threshold = threshold\n",
        "\n",
        "#     def call(self, inputs):\n",
        "#         return tf.cast(tf.where(inputs < self.threshold, 0, 1), dtype=tf.float32)"
      ],
      "metadata": {
        "id": "UwHZg7kzvqSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layer = BinarizationLayer()\n",
        "# input = tf.random.normal((1, 10))\n",
        "# input, layer(input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkpkehIVwXzn",
        "outputId": "fba9a59f-21bc-4d9c-88d8-986d59f40d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
              " array([[ 2.1678388 , -0.03977485, -1.6608976 , -0.7378837 ,  0.15050058,\n",
              "         -0.50202596,  0.8265431 ,  0.10619392,  0.42880473, -0.656575  ]],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[1., 0., 0., 0., 0., 0., 1., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def func(x):\n",
        "#     greater = K.greater_equal(x, 0.5) #will return boolean values\n",
        "#     greater = K.cast(greater, dtype=K.floatx()) #will convert bool to 0 and 1    \n",
        "#     return greater"
      ],
      "metadata": {
        "id": "JwvbLROA26Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.layers import Lambda"
      ],
      "metadata": {
        "id": "X5LhmJ9T3ZAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), padding='same',\n",
        "          activation='relu', input_shape=(50,100,1)))\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "model.add(SpatialPyramidPooling([1, 2, 4]))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(604, activation='sigmoid'))\n",
        "# model.add(\n",
        "#     Lambda(func)\n",
        "# )\n",
        "#model.add(BinarizationLayer(trainable=False))\n",
        "## arcitecture facile à comprendre et à programmer avec keras "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDuW7O8ahQqH",
        "outputId": "52eab6d6-ed21-49c8-b939-fd79ca21b177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "channels_last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = losses.binary_crossentropy\n",
        "optimizer = SGD(lr=1e-4, momentum=.9, decay=5e-5)\n",
        "model.compile(loss=loss, optimizer=optimizer, metrics=[\n",
        "    tf.keras.metrics.CosineSimilarity(),tf.keras.metrics.BinaryAccuracy(threshold = 0.1)\n",
        "    ])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc8JcItGhQs0",
        "outputId": "39e40542-0ef4-4269-af0e-2023fad1a1c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 100, 64)       640       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 50, 100, 64)       36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 25, 50, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 25, 50, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 25, 50, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 25, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 12, 25, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 12, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 12, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 12, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 12, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 12, 25, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 12, 25, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 12, 25, 512)       2359808   \n",
            "                                                                 \n",
            " spatial_pyramid_pooling (Sp  (None, 10752)            0         \n",
            " atialPyramidPooling)                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              44044288  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 604)               2474588   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 72,704,540\n",
            "Trainable params: 72,704,540\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_phocnet=model.fit(x_train,y_train,batch_size=15,epochs=30,validation_data=(x_valid, y_valid))"
      ],
      "metadata": {
        "id": "sr73bnvqh1yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5fddb53-8d91-459a-d7cd-cef0b52f4821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "162/162 [==============================] - 26s 85ms/step - loss: 0.6931 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6930 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 2/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6929 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6929 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 3/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6928 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6927 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 4/30\n",
            "162/162 [==============================] - 13s 81ms/step - loss: 0.6927 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6926 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 5/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6926 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6925 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 6/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6924 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6923 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 7/30\n",
            "162/162 [==============================] - 12s 73ms/step - loss: 0.6923 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6922 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 8/30\n",
            "162/162 [==============================] - 12s 73ms/step - loss: 0.6922 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6921 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 9/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6921 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6919 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 10/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6919 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6918 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 11/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6918 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6917 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 12/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6917 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6916 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 13/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6916 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6914 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 14/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6915 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6913 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 15/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6913 - cosine_similarity: 0.1670 - binary_accuracy: 0.0300 - val_loss: 0.6912 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 16/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6912 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6911 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 17/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6911 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6909 - val_cosine_similarity: 0.1683 - val_binary_accuracy: 0.0305\n",
            "Epoch 18/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6910 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6908 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 19/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6908 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6907 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 20/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6907 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6906 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 21/30\n",
            "162/162 [==============================] - 13s 81ms/step - loss: 0.6906 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6904 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 22/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6905 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6903 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 23/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6904 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6902 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 24/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6902 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6901 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 25/30\n",
            "162/162 [==============================] - 13s 80ms/step - loss: 0.6901 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6899 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 26/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6900 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6898 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 27/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6899 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6897 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 28/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6898 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6896 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 29/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6896 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6894 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n",
            "Epoch 30/30\n",
            "162/162 [==============================] - 12s 74ms/step - loss: 0.6895 - cosine_similarity: 0.1671 - binary_accuracy: 0.0300 - val_loss: 0.6893 - val_cosine_similarity: 0.1684 - val_binary_accuracy: 0.0305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_pred = model.predict(x_test)\n",
        "# y_pred = np.where(y_pred<0.5, 0, 1)\n",
        "# # x_test[0]\n",
        "y_pred"
      ],
      "metadata": {
        "id": "lzzkK95siBPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31fc70dc-6e1c-4df0-fbca-d2e99131258b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.00723306, 0.02719549, 0.01333661, ..., 0.00973689, 0.0147216 ,\n",
              "        0.00558952],\n",
              "       [0.00840291, 0.02962407, 0.01478983, ..., 0.01062724, 0.01639656,\n",
              "        0.0063326 ],\n",
              "       [0.00066896, 0.00501959, 0.0017162 , ..., 0.00106058, 0.00195517,\n",
              "        0.00047366],\n",
              "       ...,\n",
              "       [0.00429608, 0.01882279, 0.00842623, ..., 0.00585556, 0.00929966,\n",
              "        0.003205  ],\n",
              "       [0.00584107, 0.0232419 , 0.010988  , ..., 0.00797388, 0.01224659,\n",
              "        0.00435337],\n",
              "       [0.00056179, 0.00439022, 0.00145295, ..., 0.00085925, 0.00161612,\n",
              "        0.00039869]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(x_test, y_test, verbose = 0) \n",
        "print(score)\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "dqcxoJrZiEj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456710b2-33d9-4e91-ea98-70f9bdb4b7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.10543923825025558, 0.3644101917743683]\n",
            "Test loss: 0.10543923825025558\n",
            "Test accuracy: 0.3644101917743683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.where(y_pred<0.5, 0, 1)\n",
        "transcripts=test_transcript\n",
        "# start = datetime.now() \n",
        "N = len(transcripts)\n",
        "precision = {}\n",
        "count = {}\n",
        "for i in range(N):\n",
        "  if transcripts[i] not in precision.keys():\n",
        "    precision[transcripts[i]] = 1\n",
        "    count[transcripts[i]] = 0\n",
        "  else:\n",
        "    precision[transcripts[i]] += 1\n",
        "\n",
        "for i in range(N):\n",
        "  pred = y_pred[i]\n",
        "  acc = np.sum(abs(y_test-pred), axis=1)\n",
        "  tmp = np.argmin(acc)\n",
        "  if transcripts[tmp] == transcripts[i]:\n",
        "    count[transcripts[tmp]] += 1\n",
        "\n",
        "mean_avg_prec = [0, 0]\n",
        "for i in range(N):\n",
        "  if precision[transcripts[i]] <= 1:\n",
        "    continue\n",
        "  mean_avg_prec[0] += count[transcripts[i]]*1.0/precision[transcripts[i]] \n",
        "  mean_avg_prec[1] += 1\n",
        "result= 1.-(mean_avg_prec[0]*1./mean_avg_prec[1])\n",
        "# print (\"Time taken to calculate l2 dist: \", datetime.now() - start)\n",
        "print (\"The Mean Average Precision = \", result)\n",
        "print (\"Total test cases = \", N)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAO_hCA0eU4W",
        "outputId": "e775a462-fefb-42b6-f16c-d6e67aa62adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 1s 35ms/step\n",
            "The Mean Average Precision =  0.9759036144578314\n",
            "Total test cases =  1215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"phocnet_word_spotting_best_model.h5\")"
      ],
      "metadata": {
        "id": "bE6Lf8ugiHPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "bDPLefr4tEfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}